---
layout: page
title: Leaderboard
permalink: /leaderboard/
---

|                | Score | CLS   | PAWS-X | XNLI | POS   | DP    | VSD   | NSD   |
| -------------- | ----- | ----- | ------ | ---- | ----- | ----- | ----- | ----- |
| mBERT          | 76.09 | 86.57 | 89.3   | 76.9 | 87.52 | 89.5  | 49.83 | 53.03 |
| CamemBERT      | 78.08 | 93.38 | 90.14  | 81.2 | 88.39 | 91.37 | 50.02 | 52.06 |
| FlauBERT-base  | 77.01 | 93.22 | 89.49  | 80.6 | 89.05 | 91.56 | 43.92 | 51.24 |
| FlauBERT-large | 78.85 | 94.98 | 89.34  | 83.4 | 88.63 | 91.61 | 50.48 | 53.53 |

><sub> **Score** : Average score of all the tasks 
>
><sub> **CLS** : Text classification task with CLS dataset - Accuracy
>
><sub> **PAWS-X** : Paraphrasing task with PAWS-X dataset - Accuracy 
>
><sub> **XNLI** : Natural language inference task with XNLI dataset - Accuracy 
>
><sub> **POS** : Pos tagging task with French Treebank dataset - Accuracy 
>
><sub> **DP** : Dependency parsing task with French Treebank dataset - UAS 
>
><sub> **VSD** : Verb sense disambiguation task with French SemEval dataset - F1 
>
><sub> **NSD** : Noun sense disambiguation task with French SemEval dataset - F1 